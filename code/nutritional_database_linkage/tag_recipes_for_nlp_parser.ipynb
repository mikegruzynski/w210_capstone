{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height has been deprecated.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "pd.set_option('display.height', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import keras.preprocessing.text as kpt\n",
    "import keras\n",
    "import re \n",
    "import numpy, time\n",
    "import random\n",
    "import pickle\n",
    "from keras.models import load_model, model_from_json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_data_for_tokenizer(recipe_item):\n",
    "    original = recipe_item.lower()\n",
    "    original = re.sub(r'\\s*(\\d+|[./+*-])', '', original)\n",
    "    original_split = original.split(\" \")\n",
    "    remove_list = list(set(original).symmetric_difference(units_of_food_recipe))\n",
    "\n",
    "    keep_list = []\n",
    "    for i in original_split:\n",
    "        if i not in food_size and i not in units_of_food_recipe:\n",
    "            keep_list.append(i)\n",
    "    \n",
    "    original_split = list(filter(None, keep_list))\n",
    "    new = \" \".join(original_split)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "units_of_food_recipe = [\"cups\", \"cup\", \"c.\", \"c\", \n",
    "                        \"fl. oz.\", \"fl oz\", \"fluid ounce\", \"fluid ounces\",\n",
    "                        \"gal\", \"gal.\", \"gallon\", \"gallons\",\n",
    "                        \"oz\", \"oz.\", \"ounce\", \"ounces\", \"ouncs\",\n",
    "                        \"pt\", \"pt.\", \"pint\", \"pints\",\n",
    "                        \"lb\", \"lb.\", \"pound\", \"pounds\",\n",
    "                        \"qt\", \"qt.\", \"qts\", \"qts.\", \"quart\", \"quarts\",\n",
    "                        \"tbsp.\", \"tbsp\", \"T\", \"T.\", \"tablespoon\", \"tablespoons\", \"tbs.\", \"tbs\",\n",
    "                        \"tsp.\", \"tsp\", \"t\", \"t.\", \"teaspoon\", \"teaspoons\",\n",
    "                        \"g\", \"g.\", \"gr\", \"gr.\", \"gram\", \"grams\", \"gramme\", \"grammes\",\n",
    "                        \"kg\", \"kg.\", \"kilogram\", \"kilograms\", \"kilogramme\", \"kilogrammes\",\n",
    "                        \"l\", \"l.\", \"liter\", \"liters\", \"litre\", \"litres\",\n",
    "                        \"mg\", \"mg.\", \"milligram\", \"milligrams\", \"milligramme\", \"milligrammes\",\n",
    "                        \"ml\", \"ml.\", \"milliliter\", \"milliliters\", \"millilitre\", \"millilitres\",\n",
    "                        \"pinch\", \"pinches\", \"dash\", \"dashes\", \"touch\", \"touches\", \"handful\", \"handfuls\",\n",
    "                        \"stick\", \"sticks\",\n",
    "                        \"cans\", \"can\",\n",
    "                        \"to taste\",\n",
    "                        \"scoop\", \"scoops\",\n",
    "                        \"dollop\", \"dollops\",\n",
    "                        \"sprig\", \"sprigs\",\n",
    "                       \"recipe\",\n",
    "                       \"garnish\", \"garnished\",\n",
    "                       \"sprinkle\", \"spinkled\",\n",
    "                       \"slices\",\n",
    "                       \"serving\", \"servings\",\n",
    "                       \"ribs\", \"rib\", \"stalk\",\n",
    "                       \"inch\", \"inches\", \"in.\",\n",
    "                       \"drizzle\", \"drizzled\",\n",
    "                       \"to taste\"]\n",
    "\n",
    "food_size = [\"small\", \"medium\",\n",
    "              \"large\", \"about\"]\n",
    "\n",
    "food_format = [\"slice\", \"sliced\",\n",
    "              \"dice\", \"diced\",\n",
    "              \"peel\", \"peeled\",\n",
    "              \"chop\", \"chopped\",\n",
    "              \"julienne\", \"julienned\",\n",
    "              \"trim\", \"trimmed\",\n",
    "              \"sift\", \"sifted\",\n",
    "              \"freshly\",\n",
    "              \"fine\", \"finely\",\n",
    "              \"drain\", \"drained\",\n",
    "              \"super thinly\", \"thin\", \"thinly\",\n",
    "              \"grate\", \"grated\",\n",
    "              \"seeded\",\n",
    "              \"rinse\", \"rinsed\",\n",
    "              \"smash\", \"smashed\",\n",
    "              \"membrane\", \"removed\",\n",
    "              \"cleaned\",\n",
    "              \"mince\", \"minced\",\n",
    "              \"crush\", \"crushed\",\n",
    "              \"about\", \"around\",\n",
    "              '<hr>']\n",
    "\n",
    "\n",
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "nlp_df = pd.read_csv(\"../../data/nutrient/compiled/train_nn_df.csv\", index_col=0)\n",
    "master_df = pd.read_csv(\"../../data/nutrient/compiled/nutrition_master_df.csv\")\n",
    "\n",
    "with open('../../data/recipe/recipe_all.json') as f:\n",
    "    recipe_all = json.load(f)\n",
    "    \n",
    "with open('/root/w210_capstone/data/models/NDB_tag_unique_unique_dict.json') as f:\n",
    "        NDB_tag_unique_unique_dict = json.load(f)\n",
    "\n",
    "# loading\n",
    "with open('/root/w210_capstone/data/models/tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "    \n",
    "# load json and create model\n",
    "json_file = open('/root/w210_capstone/data/models/model_simple_nn.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"/root/w210_capstone/data/models/model_simple_nn_WEIGHTS.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5251"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "RECIPE_82087\n",
      "10 tablespoons unsalted butter plus more for the baking dish\n",
      "\t \"01145\" 0.9977 butter, without salt\n",
      "\t \"01001\" 0.0015 butter, salted\n",
      "\t \"09326\" 0.0002 watermelon, raw\n",
      "\n",
      "\n",
      "\n",
      "1 1/2 pounds assorted mushrooms (such as oyster shiitake and/or cremini) trimmed and sliced\n",
      "\t \"11987\" 0.8369 mushrooms, oyster, raw\n",
      "\t \"11238\" 0.0486 mushrooms, shiitake, raw\n",
      "\t \"11260\" 0.0224 mushrooms, white, raw\n",
      "\n",
      "\n",
      "\n",
      "Kosher salt\n",
      "\t \"02047\" 0.9994 salt, table\n",
      "\t \"10165\" 0.0003 pork, cured, salt pork, raw\n",
      "\t \"02020\" 0.0001 spices, garlic powder\n",
      "\n",
      "\n",
      "\n",
      "3 leeks (white and light green parts) halved lengthwise thinly sliced and rinsed\n",
      "\t \"11246\" 0.9973 leeks, (bulb and lower leaf-portion), raw\n",
      "\t \"20080\" 0.0004 wheat flour, whole-grain (includes foods for usda's food distribution program)\n",
      "\t \"19087\" 0.0004 candies, white chocolate\n",
      "\n",
      "\n",
      "\n",
      "1 tablespoon fresh thyme\n",
      "\t \"02049\" 0.995 thyme, fresh\n",
      "\t \"02042\" 0.0039 spices, thyme, dried\n",
      "\t \"02027\" 0.0006 spices, oregano, dried\n",
      "\n",
      "\n",
      "\n",
      "1 tablespoon finely chopped fresh rosemary\n",
      "\t \"02063\" 0.9925 rosemary, fresh\n",
      "\t \"02036\" 0.0049 spices, rosemary, dried\n",
      "\t \"18973\" 0.0005 focaccia, italian flatbread, plain\n",
      "\n",
      "\n",
      "\n",
      "2 cups low-sodium chicken or vegetable broth\n",
      "\t \"06970\" 0.6879 soup, chicken broth, low sodium, canned\n",
      "\t \"06700\" 0.2136 soup, vegetable broth, ready to serve\n",
      "\t \"06172\" 0.0631 soup, stock, chicken, home-prepared\n",
      "\n",
      "\n",
      "\n",
      "Freshly ground pepper\n",
      "\t \"02030\" 0.9866 spices, pepper, black\n",
      "\t \"02032\" 0.0064 spices, pepper, white\n",
      "\t \"02006\" 0.0028 spices, cardamom\n",
      "\n",
      "\n",
      "\n",
      "2 large eggs\n",
      "\t \"01123\" 0.9828 egg, whole, raw, fresh\n",
      "\t \"01129\" 0.0148 egg, whole, cooked, hard-boiled\n",
      "\t \"01125\" 0.0009 egg, yolk, raw, fresh\n",
      "\n",
      "\n",
      "\n",
      "1 cup heavy cream\n",
      "\t \"01053\" 0.9977 cream, fluid, heavy whipping\n",
      "\t \"01049\" 0.0007 cream, fluid, half and half\n",
      "\t \"01054\" 0.0007 cream, whipped, cream topping, pressurized\n",
      "\n",
      "\n",
      "\n",
      "1/2 cup chopped mixed fresh herbs (such as parsley tarragon and chives)\n",
      "\t \"11156\" 0.5908 chives, raw\n",
      "\t \"11297\" 0.3393 parsley, fresh\n",
      "\t \"02039\" 0.0073 spices, savory, ground\n",
      "\n",
      "\n",
      "\n",
      "16 cups 1/2-inch stale brioche cubes (1 1/2 pounds)\n",
      "\t \"18349\" 0.5407 rolls, french\n",
      "\t \"18033\" 0.3148 bread, italian\n",
      "\t \"18029\" 0.0197 bread, french or vienna (includes sourdough)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random.seed(time.time())\n",
    "ids = np.unique(list(recipe_all.keys()))\n",
    "random.shuffle(ids)\n",
    "\n",
    "original_text_list = []\n",
    "NDB_ID_list = []\n",
    "Description_list = []\n",
    "\n",
    "for recipe_id in ids[:1]:\n",
    "    print('\\n')\n",
    "    print(recipe_id)\n",
    "    \n",
    "    for ingredient in recipe_all[recipe_id]['ingredients']:\n",
    "        print(ingredient)\n",
    "        ingredient_filtered = transform_data_for_tokenizer(ingredient)\n",
    "        tokens = tokenizer.texts_to_matrix([ingredient_filtered])\n",
    "        n = 3\n",
    "        prediction = loaded_model.predict(np.array(tokens))\n",
    "\n",
    "        index_top_3_list =  loaded_model.predict(np.array(tokens)).argsort()[0][-n:][::-1]\n",
    "        NDB_top_3_list = []\n",
    "        percentage_top_3_list = []\n",
    "        for i in index_top_3_list:   \n",
    "            for key in NDB_tag_unique_unique_dict.keys():        \n",
    "                if NDB_tag_unique_unique_dict[key] == i:\n",
    "                    NDB_top_3_list.append(key)\n",
    "                    percentage_top_3_list.append(prediction[0][i])\n",
    "\n",
    "        itr = 0\n",
    "        while itr < 3:            \n",
    "            print('\\t', NDB_top_3_list[itr], round(percentage_top_3_list[itr], 4), master_df[master_df['NDB_NO'] == \"\\\"{}\\\"\".format(NDB_top_3_list[itr].strip('\"'))]['Description'].get_values()[0])\n",
    "            itr += 1\n",
    "        \n",
    "        print('\\n')\n",
    "        \n",
    "        raw_input_return = input()\n",
    "        \n",
    "        if raw_input_return == 'exit':\n",
    "            break\n",
    "        \n",
    "        else:\n",
    "            if raw_input_return:\n",
    "                original_text_list.append(ingredient)\n",
    "                NDB_ID_list.append(raw_input_return)\n",
    "                Description_list.append(master_df[master_df['NDB_NO'] == \"\\\"{}\\\"\".format(raw_input_return.strip('\"'))]['Description'].get_values()[0])\n",
    "            else:\n",
    "                if raw_input_return != 'np.nan':\n",
    "                    original_text_list.append(ingredient)\n",
    "                    NDB_ID_list.append(NDB_top_3_list[0])\n",
    "                    Description_list.append(master_df[master_df['NDB_NO'] == \"\\\"{}\\\"\".format(NDB_top_3_list[0].strip('\"'))]['Description'].get_values()[0])\n",
    "                \n",
    "\n",
    "temp_df = pd.DataFrame([original_text_list, NDB_ID_list, Description_list]).transpose()\n",
    "temp_df.columns = nlp_df.columns\n",
    "temp_df = temp_df.dropna()\n",
    "nlp_df_new = pd.concat([nlp_df, temp_df])\n",
    "nlp_df_new.to_csv(\"../../data/nutrient/compiled/train_nn_df.csv\")\n",
    "nlp_df = pd.read_csv(\"../../data/nutrient/compiled/train_nn_df.csv\", index_col=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
